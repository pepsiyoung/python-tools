# 算法工程师学习笔记整理

### 数据收集&预处理

C# 写了个程序部署在焊接机上（同品牌相机），包括图像边缘裁剪，resize 到1728 \* 320

> YOLOv5 图像像素必须能被32整除
> YOLOv5 的网络结构中，最后一层的特征图缩放为原来的 1/32，所以输入图像的长和宽都必须> >  是 32 的倍数，才能有效地利用感受野的信息。

### YOLO系列

YOLOv5是一种基于YOLOv3和YOLOv4改进的目标检测网络，它使用了新的CSP-Darknet53作为主干网络，SPPF和新的CSP-PAN作为特征融合层，以及YOLOv3 Head作为预测层。

#### 网络结构

##### 当前目前结构

```python
backbone:
  # [from, number, module, args[输入，输出，大小，步长]]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]
```

##### 结构说明

- FOCUS 模块

  图片进入backbone前，对图片进行切片操作，具体操作是在一张图片中每隔一个像素拿到一个值，类似于邻近下采样，这样就拿到了四张图片，四张图片互补，长的差不多，但是没有信息丢失，这样一来，将W、H信息就集中到了通道空间，输入通道扩充了4倍，即拼接起来的图片相对于原先的RGB三通道模式变成了12个通道，最后将得到的新图片再经过卷积操作，最终得到了没有信息丢失情况下的二倍下采样特征图。

  > 以yolov5s为例，原始的640 × 640 × 3的图像输入Focus结构，采用切片操作，先变成320 × 320 × 12的特征图，再经过一次卷积操作，最终变成320 × 320 × 32的特征图
  >
  > 作者有在[issues](https://github.com/ultralytics/yolov5/issues/847)中提到Focus是为了提速
  >
  > yolov5代码依旧在更新, 最新代码取消了Focus操作
  
- BottleneckCSP 模块
  基于CSP（Cross Stage Partial）
  **作用是在保持输入和输出特征图尺寸不变的情况下，提取和融合更多的特征信息，提高网络性能。**

  BottleneckCSP 经过三个 Bottleneck模块 之后 concat 起来，输出（128\*80\*80）

- Bottleneck 模块
  **作用：用于减少参数量和计算量，同时保持特征表达能力** 
  用于构建 CSP 架构和 C3 模块，以提高网络的效率和性能。
  
  先将channel 数减小再扩大（默认减小到一半），具体做法是先进行1×1卷积将channel减小一半，再通过3×3卷积将通道数加倍，并获取特征（共使用两个标准卷积模块），其输入与输出的通道数是不发生改变的。
  
- 使用了两种 Bottleneck 模块：
  
  1. BottleneckTrue 先是 1x1 的卷积层，然后再是 3x3 的卷积层，最后通过残差结构与初始输入相加。
  2. BottleneckFalse 先是 1x1 的卷积层，然后再是 3x3 的深度可分离卷积层，最后通过残差结构与初始输入相加。
  
- CONV 模块
  封装了三个功能：包括 **卷积(Conv2d)**、 **Batch Normalization**和 **激活函数 Swish (或者叫 SiLU)**
  
  > Swish 激活函数是一种在线性函数和 ReLU 激活函数之间非线形插值的激活函数
  >
  > Swish激活函数可以提高性能，与其他激活函数相比有更高的平均精度，缺点是会降低速度
  
- C3 模块
  一种卷积神经网络结构，替代了早期的 **BottleneckCSP模块**。
  
  **作用：提高特征提取的能力，减少计算量和内存消耗，增强特征融合和语义信息，支持多尺度预测**
  
  结构：输入特征图被分成两部分，一部分直接连接到输出，另一部分进入后续的卷积层。
  后续的卷积层包含了 3 个标准卷积层以及多个 Bottleneck 模块，其中 Bottleneck 模块的数量由配置文件中的 n 和 depth_multiple 参数乘积决定。
  最后将后续卷积层的输出与输入特征图的一部分进行拼接，得到最终的输出特征图。
  C3 模块相对于 CSP 模块不仅增加了感受野和通道数，还提高了特征图之间的交互性和语义信息。
  
- SPPF模块
  
  SPPF模块主要使用了三个5×5的MaxPool层，他是一种特殊的池化层，可以同时提取不同尺度的特征，然后将它们的输出拼接起来，可以增强特征表达能力和鲁棒性。
  
  > 替代了原先的SPP模块

#### 损失函数

YOLOv5 的总损失函数是这三种损失函数的加权和，其中每种损失函数都有一个超参数来控制其权重

##### 分类损失

用于计算预测的类别概率和真实的类别标签之间的差异，采用二值交叉熵损失函数

##### 置信度损失

用于计算预测的目标存在概率和真实的目标存在标签之间的差异，采用二值交叉熵损失函数

##### 边界框损失

用于计算预测的目标框位置和大小和真实的目标框位置和大小之间的差异，采用 GIoU 损失函数

> 增加了一个闭包区间预的惩罚项,具有 稳定性 可微性 收敛性等特点

#### 优化器

默认使用SGD，改用Adam之后效果不理想

#### 模型评估&测试

### 其他知识点

- 神经网络激活函数的意义：保证多层网络不退化成单层线性网络

- CNN 几个常用的模型  
  1. LeNet ：没啥特点，第一个CNN，用来识别邮政编码
  2. AlexNet：引入了 ReLU 和 Dropout，引入数据增强、池化之间相互有覆盖、三个卷积 + 一个最大池化 + 三个全连接
  3. VGGNet：采用 1\*1 和 3\*3 的卷积核以及 2\*2 的最大池化使得层数变的更深，常用 VGGNet-16 和 VGGNet-19
  4. Google Inspection Net：获得了比较好的分类性能，有以下几个改进
     > - 去除最后的全连接层，而是用一个全局的平均池化来取代它
     > - 引入 Inspection Module，是一个4分支结构，所有分支都用到了 1\*1 卷积，这是因为 1\*1 性价比高，用很少的参数达到非线性和特征变换。
     > - ResNet 残差神经网络，让神经元网络变得非常深
  
- 什么是梯度爆炸?
  
  在深层网络或循环神经网络中，，误差梯度在更新中积累，变成非常大的梯度，导致网络权重大幅更新，并因此使网络变得不稳定。在极端情况下，权重的值变得非常大，以至于溢出，导致 NaN 值。
  
- 梯度爆炸会引发什么问题?
  
  梯度爆炸会引起网络不稳定，最好的结果是无法从训练数据中学习，而最坏的结果是出现无法再更新权重
  
- 如何确定是否出现梯度爆炸？
  
  1. 训练过程中模型梯度快速变大
  2. 训练过程中模型权重变成 NaN 值
  3. 训练过程中，每个节点和层的误差梯度值持续超过 1.0
  
- 如何修复梯度爆炸问题？
  
  1. 重新设计层数更少的网络来解决
  2. 激活函数 Sigmoid 修改 ReLU
  
- 神经网络中，哪些方法可以防止过拟合？
  
  1. Dropout
  2. 加L1/L2正则化
  3. BatchNormalization
  4. 提前终止训练
  5. 数据增强，增加样本
  
- One-stage & Two-stage
  
  **One-stage：**CNN 特征 -> 区域分类位置精修
  
  > 直接回归物体的类别概率和位置坐标值（无region proposal）
  
  优点：速度快、避免背景错误，产生false positives，学到物体的泛化特征
  
  缺点：精度低（定位、检出率）、小物体检测效果不好
  
  **Two-stage：**产生候选区域 CNN 特征 -> RPN（区域间隔网络）产生候选区域 -> 区域分类位置精修
  
  优点：精度高（定位、检出率）、共享计算量
  
  缺点：速度慢、训练时间长、误报高
  
### 快速排序

```python
def quick_sort(nums):
    n = len(nums)

    def quick(left, right):
        if left >= right:
            return nums
        pivot = left
        i = left
        j = right
        while i < j:
            while i < j and nums[j] > nums[pivot]:
                j -= 1
            while i < j and nums[i] <= nums[pivot]:
                i += 1
            nums[i], nums[j] = nums[j], nums[i]
        nums[pivot], nums[j] = nums[j], nums[pivot]
        quick(left, j - 1)
        quick(j + 1, right)
        return nums

    return quick(0, n - 1)
```



  

  

  

  

  

